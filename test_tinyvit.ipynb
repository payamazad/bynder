{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453907ad-3e04-493e-9fac-0bd099f2c708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.10 (main, Aug 27 2024, 07:11:23) [Clang 15.0.0 (clang-1500.3.9.4)]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd66bc5b-c66a-4f20-b179-0459b2d80464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "../../dataset/images/10001.jpg\n",
      "miniskirt: 0.60\n",
      "jeans: 0.23\n",
      "lampshade: 0.01\n",
      "swim trunks / shorts: 0.00\n",
      "knee pad: 0.00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Model Inference.\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from models.tiny_vit import tiny_vit_21m_224\n",
    "from data import build_transform, imagenet_classnames\n",
    "from config import get_config\n",
    "\n",
    "config = get_config()\n",
    "\n",
    "\n",
    "# Build model\n",
    "model = tiny_vit_5m_224(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Load Image\n",
    "fname = \"../../dataset/images/10001.jpg\"\n",
    "image = Image.open(fname)\n",
    "transform = build_transform(is_train=False, config=config)\n",
    "\n",
    "# (1, 3, img_size, img_size)\n",
    "batch = transform(image)[None]\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(batch)\n",
    "\n",
    "# print top-5 classification names\n",
    "probs = torch.softmax(logits, -1)\n",
    "scores, inds = probs.topk(5, largest=True, sorted=True)\n",
    "print('=' * 30)\n",
    "print(fname)\n",
    "for score, ind in zip(scores[0].numpy(), inds[0].numpy()):\n",
    "    print(f'{imagenet_classnames[ind]}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32df4a85-06c4-4d83-8d6e-6ad5b9d723f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "../../dataset/images/10001.jpg\n",
      "jeans: 0.28\n",
      "miniskirt: 0.12\n",
      "punching bag: 0.09\n",
      "baby pacifier: 0.01\n",
      "messenger bag: 0.01\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Model Inference.\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from models.tiny_vit import tiny_vit_5m_224\n",
    "from data import build_transform, imagenet_classnames\n",
    "from config import get_config\n",
    "\n",
    "config = get_config()\n",
    "\n",
    "\n",
    "# Build model\n",
    "model = tiny_vit_5m_224(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Load Image\n",
    "fname = \"../../dataset/images/10001.jpg\"\n",
    "image = Image.open(fname)\n",
    "transform = build_transform(is_train=False, config=config)\n",
    "\n",
    "# (1, 3, img_size, img_size)\n",
    "batch = transform(image)[None]\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(batch)\n",
    "\n",
    "# print top-5 classification names\n",
    "probs = torch.softmax(logits, -1)\n",
    "scores, inds = probs.topk(5, largest=True, sorted=True)\n",
    "print('=' * 30)\n",
    "print(fname)\n",
    "for score, ind in zip(scores[0].numpy(), inds[0].numpy()):\n",
    "    print(f'{imagenet_classnames[ind]}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c411c5e-5453-4636-9858-32b266092daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyViT(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (seq): Sequential(\n",
      "      (0): Conv2d_BN(\n",
      "        (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d_BN(\n",
      "        (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0): ConvLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0-1): 2 x MBConv(\n",
      "          (conv1): Conv2d_BN(\n",
      "            (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (act1): GELU(approximate='none')\n",
      "          (conv2): Conv2d_BN(\n",
      "            (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (act2): GELU(approximate='none')\n",
      "          (conv3): Conv2d_BN(\n",
      "            (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (act3): GELU(approximate='none')\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (act): GELU(approximate='none')\n",
      "        (conv1): Conv2d_BN(\n",
      "          (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): Conv2d_BN(\n",
      "          (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv3): Conv2d_BN(\n",
      "          (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): BasicLayer(\n",
      "      dim=128, input_resolution=(28, 28), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0-1): 2 x TinyViTBlock(\n",
      "          dim=128, input_resolution=(28, 28), num_heads=4, window_size=7, mlp_ratio=4.0\n",
      "          (drop_path): Identity()\n",
      "          (attn): Attention(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (mlp): Mlp(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (local_conv): Conv2d_BN(\n",
      "            (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (act): GELU(approximate='none')\n",
      "        (conv1): Conv2d_BN(\n",
      "          (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): Conv2d_BN(\n",
      "          (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv3): Conv2d_BN(\n",
      "          (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): BasicLayer(\n",
      "      dim=160, input_resolution=(14, 14), depth=6\n",
      "      (blocks): ModuleList(\n",
      "        (0-5): 6 x TinyViTBlock(\n",
      "          dim=160, input_resolution=(14, 14), num_heads=5, window_size=14, mlp_ratio=4.0\n",
      "          (drop_path): Identity()\n",
      "          (attn): Attention(\n",
      "            (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
      "            (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
      "            (proj): Linear(in_features=160, out_features=160, bias=True)\n",
      "          )\n",
      "          (mlp): Mlp(\n",
      "            (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
      "            (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (local_conv): Conv2d_BN(\n",
      "            (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
      "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (act): GELU(approximate='none')\n",
      "        (conv1): Conv2d_BN(\n",
      "          (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): Conv2d_BN(\n",
      "          (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=320, bias=False)\n",
      "          (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv3): Conv2d_BN(\n",
      "          (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): BasicLayer(\n",
      "      dim=320, input_resolution=(7, 7), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0-1): 2 x TinyViTBlock(\n",
      "          dim=320, input_resolution=(7, 7), num_heads=10, window_size=7, mlp_ratio=4.0\n",
      "          (drop_path): Identity()\n",
      "          (attn): Attention(\n",
      "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "            (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
      "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          )\n",
      "          (mlp): Mlp(\n",
      "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (local_conv): Conv2d_BN(\n",
      "            (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm_head): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  (head): Linear(in_features=320, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee6504aa-fcf7-45fb-9208-4d7b37d6f534",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.head = torch.nn.Linear(model.head.in_features, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "380d90a9-01ae-4b85-b571-e648b6d37a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyViT(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (seq): Sequential(\n",
      "      (0): Conv2d_BN(\n",
      "        (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Conv2d_BN(\n",
      "        (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0): ConvLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0-1): 2 x MBConv(\n",
      "          (conv1): Conv2d_BN(\n",
      "            (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (act1): GELU(approximate='none')\n",
      "          (conv2): Conv2d_BN(\n",
      "            (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (act2): GELU(approximate='none')\n",
      "          (conv3): Conv2d_BN(\n",
      "            (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (act3): GELU(approximate='none')\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (act): GELU(approximate='none')\n",
      "        (conv1): Conv2d_BN(\n",
      "          (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): Conv2d_BN(\n",
      "          (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv3): Conv2d_BN(\n",
      "          (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): BasicLayer(\n",
      "      dim=128, input_resolution=(28, 28), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0-1): 2 x TinyViTBlock(\n",
      "          dim=128, input_resolution=(28, 28), num_heads=4, window_size=7, mlp_ratio=4.0\n",
      "          (drop_path): Identity()\n",
      "          (attn): Attention(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (mlp): Mlp(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (local_conv): Conv2d_BN(\n",
      "            (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (act): GELU(approximate='none')\n",
      "        (conv1): Conv2d_BN(\n",
      "          (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): Conv2d_BN(\n",
      "          (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv3): Conv2d_BN(\n",
      "          (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): BasicLayer(\n",
      "      dim=160, input_resolution=(14, 14), depth=6\n",
      "      (blocks): ModuleList(\n",
      "        (0-5): 6 x TinyViTBlock(\n",
      "          dim=160, input_resolution=(14, 14), num_heads=5, window_size=14, mlp_ratio=4.0\n",
      "          (drop_path): Identity()\n",
      "          (attn): Attention(\n",
      "            (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
      "            (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
      "            (proj): Linear(in_features=160, out_features=160, bias=True)\n",
      "          )\n",
      "          (mlp): Mlp(\n",
      "            (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
      "            (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (local_conv): Conv2d_BN(\n",
      "            (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
      "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        (act): GELU(approximate='none')\n",
      "        (conv1): Conv2d_BN(\n",
      "          (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): Conv2d_BN(\n",
      "          (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=320, bias=False)\n",
      "          (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv3): Conv2d_BN(\n",
      "          (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): BasicLayer(\n",
      "      dim=320, input_resolution=(7, 7), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0-1): 2 x TinyViTBlock(\n",
      "          dim=320, input_resolution=(7, 7), num_heads=10, window_size=7, mlp_ratio=4.0\n",
      "          (drop_path): Identity()\n",
      "          (attn): Attention(\n",
      "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "            (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
      "            (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          )\n",
      "          (mlp): Mlp(\n",
      "            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "            (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (local_conv): Conv2d_BN(\n",
      "            (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
      "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm_head): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "  (head): Linear(in_features=320, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb8c8f-4faf-4c2c-afcb-da32998d6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchview import draw_graph\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "# device='meta' -> no memory is consumed for visualization\n",
    "model_graph = draw_graph(model, input_size=(batch_size,3, 224, 224), device='meta')\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb007f-ec35-4cc3-9389-50ae9eef8e27",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a29a4f-1207-45cc-a87c-526558871afc",
   "metadata": {},
   "source": [
    "## Gender prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb90735-3b26-4a91-9adc-f08918888f17",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb2a65-5ec4-4963-8be0-4b49396c135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, str(self.img_labels.iloc[idx, 0])+\".jpg\")\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 2]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
